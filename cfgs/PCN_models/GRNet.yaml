# optimizer: {
#   type: Adam,
#   kwargs: {
#   lr : 0.0001, 
#   weight_decay : 0
# }}
# scheduler: {
#   type: StepLR,
#   kwargs: {
#   step_size: 50,
#   gamma : 0.5
# }}

optimizer: {
  type: AdamW,
  kwargs: {
    lr: 0.0001,
    weight_decay: 0.001
  }
}

scheduler: {
  type: CosLR,
  kwargs: {
    t_max: 150,
    min_lr: 0.000001,
    initial_epochs: 10,
    warmup_lr_init: 0.00001,
    t_in_epochs: True
  }
}


dataset : {
  train : { _base_: cfgs/dataset_configs/ShapeNet_Car_Seq.yaml, 
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset_configs/ShapeNet_Car_Seq.yaml, 
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/ShapeNet_Car_Seq.yaml, 
            others: {subset: 'test'}}}
model : {
  NAME: GRNet, num_pred: 16384, gridding_loss_scales: 128, gridding_loss_alphas: 0.1}
total_bs : 8   #32*1
step_per_update : 8
max_epoch : 150

consider_metric: CDL1
patience: 30