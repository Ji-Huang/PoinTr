optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.00004,  #0.0005
  weight_decay : 0.0005 #0.0005  w0.001
}}

#scheduler: {
#  type: LambdaLR,
#  kwargs: {
#  decay_step: 21,
#  lr_decay: 0.9,
#  lowest_decay: 0.02  # min lr = lowest_decay * lr
#}}

scheduler: {
  type: CosLR,
  kwargs: {
    t_max: 320,               # This corresponds to t_initial in the scheduler
    min_lr: 0.000001,            # This corresponds to lr_min in the scheduler
    initial_epochs: 10,       # This corresponds to warmup_t in the scheduler  #10 4
    warmup_lr_init: 0.00001,
    t_in_epochs: True
}}

bnmscheduler: {
  type: Lambda,
  kwargs: {
  decay_step: 30, #21
  bn_decay: 0.5,
  bn_momentum: 0.9,
  lowest_decay: 0.05 #0.01
}}

dataset : {
  train : { _base_: cfgs/dataset_configs/ShapeNet_Car_Seq.yaml,
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset_configs/ShapeNet_Car_Seq.yaml,
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/ShapeNet_Car_Seq.yaml,
            others: {subset: 'test'}}}
model : {
  NAME: PoinTr, num_pred: 16128, num_query: 252, knn_layer: 1, trans_dim: 384} #nq 224 np 14336
  
total_bs : 48 # 48
step_per_update : 8 # 1   #me 80,step=4.    me 160,step=6
max_epoch : 320

patience: 30    #20

consider_metric: CDL1